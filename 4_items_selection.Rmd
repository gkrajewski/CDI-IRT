---
title: "Items selection"
author: "Piotr Kr√≥l"
date: "29 06 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
```

Content:

* Items used in simulations
  + SE 0.173 stop criterion
  + SE 0.173 + 50 max items stop criterion
* Models with restricted set of items (146)
  + mirt 61 quadratures
  + mirt 101 quadratures
  + mirt 61 quadratures no easy items (146 - 2)
  + mirt 101 quadratures no easy items
  + mirt 151 quadratures no easy items
  + ltm 101 quadratures no easy items
  + ltm 101 quadratures + 472 iterations no easy items
  + TAM default
  + TAM 101 snodes
* CTT difficulty and discrimination

```{r libraries, message=FALSE, warning=FALSE}
library(mirt)
library(mirtCAT)
library(parallel) #Speeds up simulations (many in parallel)
library(plyr) #For laply
library(ggpubr) #For making plots
library(ltm)
library(TAM)
```

Load already prepared responses & cdi content:

```{r message=FALSE}
responses_demo <- read.csv("Data/responses_demo.csv", encoding = "UTF-8")
responses <- as.matrix(responses_demo[,5:ncol(responses_demo)])
cdi <- read.csv("Data/cdi.csv", encoding = "UTF-8")
```

# Items used in simulations

Load best *mirt* model with 601 quadratures (the highest log-likelihood ever obtained):

```{r}
load("Data/mirt_model_601q")
mirt_model
```

```{r}
mirt_params <- as.data.frame(coef(mirt_model, simplify = TRUE)$items)[1:2]
head(mirt_params)
```

## SE 0.173 stop criterion

Simulate CAT with just SE stop criterion:

```{r eval=FALSE}
mo <- generate.mirt_object(mirt_params, '2PL')
design <- list(min_SEM = 0.173) #0.173 corresponds to reliability of 0.97 (which is Polish CDI:WS words reliability)
cl <- makeCluster(detectCores()) #Speeds up simulations (many in paralell)
sim_results <- mirtCAT(mo = mo, method = "MAP", criteria = "MI", start_item = "MI", local_pattern = responses, cl = cl, design = design)
```

```{r include=FALSE}
load("Data/sim_results")
```

Investigate tests lengths needed to achieve stop criterion (SE<=0.173):

```{r}
#Obtain lengths
tests_lengths <- laply(sim_results, function(x) length(x$items_answered))

#Prepare cuts
cuts <- cut(tests_lengths, breaks = c(0, 10, 20, 50, 100, 200, 669, 670), labels = c("1 - 10", "11 - 20", "21 - 50", "51 - 100", "101 - 200", "201 - 669", "670"), dig.lab = 0)
df_freq <- as.data.frame(table(cuts))

#Plot distribution
ggplot(df_freq, aes(x = cuts, y = Freq)) +
  xlab("Number of items in test") +
  ylab("Number of tests") +
  geom_bar(stat = "identity") +
  ggtitle(paste0("\nAverage test length: ", round(mean(tests_lengths), 2))) +
  geom_text(aes(label = Freq), vjust = -0.3) + 
  theme_pubclean() 
```

Calculate frequency of occurence of particular items:

```{r}
#Prepare df with frequencies of usage of items
frequency_df <- data.frame(number.ws = c(1:nrow(mirt_params)), freq = rep(0, nrow(mirt_params)))

#Update df with number of occurence of given item
for (p in 1:length(sim_results)){
  items <- sim_results[[p]]$items_answered
  for (number.ws in items){
    frequency_df[frequency_df["number.ws"] == number.ws, "freq"] <- frequency_df[frequency_df["number.ws"] == number.ws, "freq"] + 1
  }
}
head(frequency_df)
```

Add cdi info about items

```{r}
items_usage <- merge(frequency_df, cdi, by="number.ws")
row.names(items_usage) <- NULL
head(items_usage)
```

Calculate frequency in percents and order by it

```{r}
items_usage$freq <- items_usage$freq / length(sim_results)
items_usage <- items_usage[order(items_usage$freq, decreasing = T), ]
head(items_usage)
```

Investigate frequency intervals:

```{r}
#Prepare cuts
cuts <- cut(items_usage$freq, breaks = c(0, 0.06, 0.07, 0.08, 0.1, 0.2,  1), labels = c("0 - 6%", "6 - 7%", "7 - 8%", "8 - 10%", "10 - 20%", "20-100%"), dig.lab = 0)
df_freq <- as.data.frame(table(cuts))

#Plot distribution
ggplot(df_freq, aes(x = cuts, y = Freq)) +
  xlab("Frequency of usage") +
  ylab("Number of items") +
  geom_bar(stat = "identity") +
  geom_text(aes(label = Freq), vjust = -0.3) + 
  theme_pubclean() 
```

Select top 100 items and check their category belonging:

```{r}
best_items <- items_usage[1:100, ]
table(best_items$category)
```

So there are generally different categories. Let's check what are the parameters (IRT parametrization) of top 100 items:

```{r fig.width=12}
#Prepare df with only best items with IRT params
best_items_ids <- paste0("item", best_items$number.ws)
mirt_params_IRT <- as.data.frame(coef(mirt_model, simplify = TRUE, IRTpars = TRUE)$items)[1:2]
mirt_params_IRT_best <- mirt_params_IRT[best_items_ids, ]
mirt_params_IRT_best <- cbind(mirt_params_IRT_best, best_items)

#Create plot
ggplot(mirt_params_IRT_best, aes(b, a, colour = category)) +
  geom_point() +
  xlab("Difficulty") +
  ylab("Discrimination")
```

See what are parameters of the best items w.r.t parameters of all items:

```{r fig.width=12}
#Prepare df with all params
mirt_params_IRT <- cbind(mirt_params_IRT, cdi)
mirt_params_IRT$top100 <- FALSE
mirt_params_IRT[best_items_ids, "top100"] <- TRUE

#Create plot
ggplot(mirt_params_IRT, aes(b, a, colour = top100)) +
  geom_point() +
  xlab("Difficulty") +
  ylab("Discrimination") +
  labs(colour = "Top 100") +
  scale_color_manual(values = c("Black", "Green"))
```

## SE 0.173 + 50 max items stop criterion

```{r}
mo <- generate.mirt_object(mirt_params, '2PL')
design <- list(min_SEM = 0.173, max_items = 50)
cl <- makeCluster(detectCores())
sim_results <- mirtCAT(mo = mo, method = "MAP", criteria = "MI", start_item = "MI", local_pattern = responses, cl = cl, design = design)
```

Investigate tests lengths needed to achieve stop criterion (SE<=0.173 + max 50 items):

```{r}
#Obtain lengths
tests_lengths <- laply(sim_results, function(x) length(x$items_answered))

#Prepare cuts
cuts <- cut(tests_lengths, breaks = c(0, 10, 20, 30, 40, 49, 50), labels = c("1 - 10", "11 - 20", "21 - 30", "31 - 40", "41 - 49", "50"), dig.lab = 0)
df_freq <- as.data.frame(table(cuts))

#Plot distribution
ggplot(df_freq, aes(x = cuts, y = Freq)) +
  xlab("Number of items in test") +
  ylab("Number of tests") +
  geom_bar(stat = "identity") +
  ggtitle(paste0("\nAverage test length: ", round(mean(tests_lengths), 2))) +
  geom_text(aes(label = Freq), vjust = -0.3) + 
  theme_pubclean() 
```

```{r}
#Prepare df with frequencies of usage of items
frequency_df <- data.frame(number.ws = c(1:nrow(mirt_params)), freq = rep(0, nrow(mirt_params)))

#Update df with number of occurence of given item
for (p in 1:length(sim_results)){
  items <- sim_results[[p]]$items_answered
  for (number.ws in items){
    frequency_df[frequency_df["number.ws"] == number.ws, "freq"] <- frequency_df[frequency_df["number.ws"] == number.ws, "freq"] + 1
  }
}

#Add cdi info about items
items_usage <- merge(frequency_df, cdi, by="number.ws")
row.names(items_usage) <- NULL

#Calculate frequency by percents and order by it
items_usage$freq <- items_usage$freq / length(sim_results)
items_usage <- items_usage[order(items_usage$freq, decreasing = T), ]
head(items_usage)
```

```{r}
#Prepare cuts
cuts <- cut(items_usage$freq, breaks = c(0, 0.05, 0.1, 0.15, 0.2, 0.3, 1), labels = c("0 - 5%", "5 - 10%", "10 - 15%", "15 - 20%", "20 - 30%", "30 - 100%"), dig.lab = 0)
df_freq <- as.data.frame(table(cuts))

#Plot distribution
ggplot(df_freq, aes(x = cuts, y = Freq)) +
  xlab("Frequency of usage") +
  ylab("Number of items") +
  geom_bar(stat = "identity") +
  geom_text(aes(label = Freq), vjust = -0.3) + 
  ggtitle(paste0("Number of used items: ", length(which(items_usage$freq > 0)))) +
  theme_pubclean() 
```

Parameters of used 146 items:

```{r fig.width=12}
best_items <- items_usage[1:length(which(items_usage$freq > 0)), ]

#Prepare df with only used items with IRT params
best_items_ids <- paste0("item", best_items$number.ws)
mirt_params_IRT <- as.data.frame(coef(mirt_model, simplify = TRUE, IRTpars = TRUE)$items)[1:2]
mirt_params_IRT_best <- mirt_params_IRT[best_items_ids, ]
mirt_params_IRT_best <- cbind(mirt_params_IRT_best, best_items)

#Create plot
ggplot(mirt_params_IRT_best, aes(b, a, colour = category)) +
  geom_point() +
  xlab("Difficulty") +
  ylab("Discrimination")
```

Parameters of used 146 w.r.t. all items:

```{r fig.width=12}
#Prepare df with all params
mirt_params_IRT <- cbind(mirt_params_IRT, cdi)
mirt_params_IRT$top100 <- FALSE
mirt_params_IRT[best_items_ids, "top100"] <- TRUE

#Create plot
ggplot(mirt_params_IRT, aes(b, a, colour = top100)) +
  geom_point() +
  xlab("Difficulty") +
  ylab("Discrimination") +
  labs(colour = "In used 146") +
  scale_color_manual(values = c("Black", "Green"))
```

# Models with restricted set of items

Let's create models with 146 items that was used during last simulations:

## mirt 61 quadratures

```{r}
responses_r <- responses[,best_items_ids]
```

```{r results='hide', eval = FALSE}
mirt_model <- mirt(responses_r, 1, SE=TRUE)
```

```{r include=FALSE}
load("Data/mirt_model_146r")
```

```{r}
mirt_model
```

```{r}
mirt_params <- as.data.frame(coef(mirt_model, simplify = TRUE)$items)[1:2]
head(mirt_params)
```

Let's check if increasing number of quadratures changes something here:

## mirt 101 quadratures

```{r results='hide', eval=FALSE}
mirt_model <- mirt(responses_r, 1, SE=TRUE, quadpts = 101)
```

```{r include=FALSE}
load("Data/mirt_model_146r_101q")
```

```{r}
mirt_model
```

```{r}
mirt_params <- as.data.frame(coef(mirt_model, simplify = TRUE)$items)[1:2]
head(mirt_params)
```

So there's gain in Log-likelihood and parameters are a bit different. Let's check if there are any ceiling or floor items:

## mirt 61 quadratures no easy items

```{r}
difficulties <- colSums(responses_r) / nrow(responses_r)
```

```{r}
any(difficulties > 0.95)
```

```{r}
which(difficulties > 0.95)
```

```{r}
any(difficulties < 0.05)
```

Let's remove very easy items:

```{r}
responses_r <- responses[, best_items_ids[!best_items_ids %in% names(which(difficulties > 0.95))]]
ncol(responses_r)
```

And again create model:

```{r results='hide', eval = FALSE}
mirt_model <- mirt(responses_r, 1, SE=TRUE)
```

```{r include=FALSE}
load("Data/mirt_model_r")
```

```{r}
mirt_model
```

```{r}
mirt_params <- as.data.frame(coef(mirt_model, simplify = TRUE)$items)[1:2]
head(mirt_params)
```

## mirt 101 quadratures no easy items

```{r results='hide', eval=FALSE}
mirt_model <- mirt(responses_r, 1, SE=TRUE, quadpts = 101)
```

```{r include=FALSE}
load("Data/mirt_model_101q_r")
```

```{r}
mirt_model
```

```{r}
mirt_params <- as.data.frame(coef(mirt_model, simplify = TRUE)$items)[1:2]
head(mirt_params)
```

So still *model with higher number of quadratures gains Log-Likelihood even without these very easy items*. Let's check if there is more precision to gain with higher number of quadratures:

## mirt 151 quadratures no easy items

```{r results='hide', eval=FALSE}
mirt_model <- mirt(responses_r, 1, SE=TRUE, quadpts = 151, technical=list(NCYCLES=3000))
```

```{r include=FALSE}
load("Data/mirt_model_151q_r")
```

```{r}
mirt_model
```

```{r}
mirt_params <- as.data.frame(coef(mirt_model, simplify = TRUE)$items)[1:2]
head(mirt_params)
```

No further improvement, yay! So *101 quadratures is optimal number here*. Let's check ltm results:

## ltm 101 quadratures no easy items

```{r eval=FALSE}
ltm_model <- ltm(responses_r ~ z1, IRT.param = FALSE, control = list(GHk = 101))
```

```{r include=FALSE}
load("Data/ltm_model_101q_r")
```

```{r}
summary(ltm_model)$logLik
```

```{r}
ltm_params <- as.data.frame(coef(ltm_model))
head(ltm_params)
```

## ltm 101 quadratures + 472 iterations no easy items

Number of iterations is analogous to what mirt had.

```{r eval=FALSE}
ltm_model <- ltm(responses_r ~ z1, IRT.param = FALSE, control = list(iter.em = 472, GHk = 101))
```

```{r include=FALSE}
load("Data/ltm_model_101q_472i_r")
```

```{r}
summary(ltm_model)$logLik
```

```{r}
ltm_params <- as.data.frame(coef(ltm_model))
head(ltm_params)
```

## TAM default

```{r results='hide'}
tam_model <- tam.mml.2pl(responses_r, irtmodel="2PL")
```

```{r}
tam_model
```

```{r}
tam_params<-data.frame(a1=tam_model$item[,"B.Cat1.Dim1"], d=tam_model$xsi$xsi)
head(tam_params)
```

# TAM 101 snodes

```{r results='hide', eval=FALSE}
tam_model <- tam.mml.2pl(responses_r, irtmodel="2PL", control=list(snodes = 101, QMC=FALSE))
```

```{r include=FALSE}
load("Data/tam_model_101s_r")
```

```{r}
tam_model
```

```{r}
tam_params<-data.frame(a1=tam_model$item[,"B.Cat1.Dim1"], d=tam_model$xsi$xsi)
head(tam_params)
```

# CTT difficulty and discrimination

```{r}
difficulties <- colSums(responses) / nrow(responses)
discriminations <- c()
row_sums <- rowSums(responses)

for (item in colnames(responses)){
  item_responses <- responses[,item]
  cor <- cor(item_responses, row_sums)
  discriminations <- c(discriminations, cor)
}

ctt_params <- data.frame(Dffclt = difficulties, Dscrmn = discriminations)

ggplot(ctt_params, aes(Dffclt, Dscrmn)) +
  geom_point() +
  xlab("Difficulty") +
  ylab("Discrimination")
```